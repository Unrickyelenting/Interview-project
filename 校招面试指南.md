# 面试的目的和理念
- 面试不需要面面俱到，被考倒也不用紧张，重点在于展现自己的优点、学习能力
- 不清楚的地方不要强行装懂回答，实话实说，可以表明自己不清楚后尝试聊聊自己对这个问题的想法或者一些相似的问题如何解决
- 校招面试重在基础、潜力，内容以学校中能学到的为主，其他方面只会作为加分项
- 面试一定是有运气成分在的，不同的面试官在喜好、要求上总会有一些差异，且或多或少会受当天心情影响。不同部门的要求也会有差异，因此面试失败不用太过在意，个别offer不一定能体现自己的水平，失败了几次也不会说明投其他公司不能成功


# 面试内容整理

## 编程语言
主要分为理论与编码两个部分。编码通常结合算法一起考察。算法和编码为两个维度，编码能力主要考验面试者能否清晰地将自己的想法、逻辑用代码表示，在整个过程中查看编码熟练度、debug能力、代码设计质量等方面

编码部分：
- 编写效率：一个考察点，在规定时间内完成即可，不必太过追求时间
- 代码质量：检查边界情况与异常情况等
- 代码结构设计：就算是算法题也最好保持较好的可读性，风格规范，变量命名在不会太长的前提下体现意义。

语言部分：
- 基础要求：大部分熟练掌握且能应用在代码中
- 进阶要求：作为加分项
- 设计模式：作为加分项

### 大纲

#### C/C++
1. 基础知识:类、继承、多态、虚函数
    1. 基础要求
        1. 继承、虚函数、多态；抽象类、纯虚函数；虚析构函数
        
        继承：子类继承父类的特征和行为，子类有父类的非private方法或成员变量，子类可以对
        父类的方法进行重写，增强了类之间的耦合性，但是当被final修饰时不能继承
        
        虚函数：是在基类中使用关键字 virtual 声明的函数。在派生类中重新定义基类中定义的
        虚函数时，会告诉编译器不要静态链接到该函数。我们想要的是在程序中任意点可以根据所
        调用的对象类型来选择调用的函数. 基类创建虚函数时会生成一个虚函数表.
        
        多态：多态就是不同继承类的对象，对同一信息做出的不同相应，基类的指针指向或绑定到
        派生类的对象，使得基类指针呈现出不同的表现方式.
        
	例子：
	#include <iostream>
	using namespace std;
	class A
	{
	public:
	    int i;
	    virtual void func() {}
	    virtual void func2() {}
	};
	class B : public A
	{
	    int j;
	    void func() {}
	};
	int main()
	{
	    cout << sizeof(A) << ", " << sizeof(B);  //输出 8,12
	    return 0;
	}
	在 32 位编译模式下，程序的运行结果是：
	8, 12

	如果将程序中的 virtual 关键字去掉，输出结果变为：
	4, 8
	
	![image](https://user-images.githubusercontent.com/91724438/148627681-677cf07f-bdd8-47a6-8a45-61d9070acff9.png)
	![image](https://user-images.githubusercontent.com/91724438/148627687-3c2d3a66-74f2-4107-9e92-cde0e2e8bd41.png)
	虚函数的地址保存在虚函数表中，在类的对象所在的内存空间中，保存了指向虚函数表的指针（称为“虚表指针”），通过虚表指针可以找到类对应的虚函数表。虚函数表解决了基类和派生类的继承问题和类中成员函数的覆盖问题，当用基类的指针来操作一个派生类的时候，这张虚函数表就指明了实际应该调用的函数。各个对象中包含的 4 个字节的虚函数表的地址都是空间上的额外开销；而查虚函数表的过程则是时间上的额外开销。
	
        抽象类：含有纯虚函数的类称为抽象类，类中只有接口没有具体实现方法，继承的如果没有
        完全实现基类纯虚函数他还是抽象类.
        
        纯虚函数在类中声明加上=0.实现机制：虚函数通过虚函数表来实现。


        
        虚析构函数最好，对于继承关系的类，这样可以根据不同类的不同特质释放内存.析构函数
        定义成虚函数是为了防止内存泄漏，因为当基类的指针或者引用指向或绑定到派生类的对象
        时，如果未将基类的析构函数定义成虚函数，会调用基类的析构函数，那么只能将基类的成
        员所占的空间释放掉，派生类中特有的就会无法释放内存空间导致内存泄漏。

        
        2. 内部类简单使用
        内部类就是外部类的友元类。注意友元类的定义，内部类可以通过外部类的对象参数来访问
        外部类中的所有成员。但是外部类不是内部类的友元.
        内部类可以定义在外部类的public、protected、private都是可以的.
        内部类可以直接访问外部类中的static、枚举成员，不需要外部类的对象/类名.
        内部类可以现在外部类中声明，然后在外部类外定义.
        
        3. 访问控制：public、protected、private（与struct对比）；友元类、友元函数
        1.private成员只能被本类成员（类内）和友元访问，不能被派生类访问；
		2.protected成员可以被派生类访问。
		继承时访问属性.
		1.public继承：基类public成员，protected成员，private成员的访问属性在派生类中分别变成：public, protected, private
		2.protected继承：基类public成员，protected成员，private成员的访问属性在派生类中分别变成：protected, protected, private
		3.private继承：基类public成员，protected成员，private成员的访问属性在派生类中分别变成：private, private, private
		友元类可以访问所有类型的成员
		派生类包含了基类和所有派生类中的函数，同名的话基类被隐藏.
        
        4. 函数重载、运算符重载
        重载：同一可访问区内被声明几个具有不同参数列的同名函数，根据参数列表确定调用哪个，
        返回类型不同不能重载.
        运算符重载 a operator+(const a&);
        
        5. 复制构造函数
        如果一个类拥有资源，该类的对象进行复制时，如果资源重新分配，就是深拷贝，否则就是
        浅拷贝。
        当类的成员变量中有指针变量时，最好使用深拷贝。因为当两个对象指向同一块内存空间，
        如果使用浅拷贝，当其中一个对象的删除后，该块内存空间就会被释放，另外一个对象指向
        的就是垃圾内存。


        6. const、static基本使用
	
	7. 拷贝构造函数的函数参数传递必须加&
	f如果不加& 会导致递归调用.如：
	
	test a(ort）; --> test.a(test t=ort)==test.a(test t(ort))
              -->test.a(test t(test t = ort))
                 ==test.a(test t(test t(ort)))
              -->test.a(test t(test t(test t=ort)))
    2. 进阶要求
        1. 虚函数表 
        虚函数的地址保存在虚函数表中，在类的对象所在的内存空间中，保存了指向虚函数表的指
        针（称为“虚表指针”），通过虚表指针可以找到类对应的虚函数表。虚函数表解决了基类和
        派生类的继承问题和类中成员函数的覆盖问题，当用基类的指针来操作一个派生类的时候，
        这张虚函数表就指明了实际应该调用的函数。
        虚函数表相关知识点：
		虚函数表存放的内容：类的虚函数的地址。
		虚函数表建立的时间：编译阶段，即程序的编译过程中会将虚函数的地址放在虚函数表中。
		虚表指针保存的位置：虚表指针存放在对象的内存空间中最前面的位置，这是为了保证正确取到虚函数的偏移量。
        2. [内联函数](https://www.runoob.com/cplusplus/cpp-inline-functions.html)
        普通函数函数调用过程：1.函数调用 2.保存现场，3.执行函数 4.回复现场.
        内联函数调用： 在编译时直接将代码段放入代码栈中
		优点：减少了函数调用过程中的资源消耗.
		缺点：损耗内存.将一个内联函数调用十次相当于在内存中复制十次代码段.而普通函数时调用十次只需要保存一次的代码段
        3. [仿函数functor的使用](https://stackoverflow.com/questions/356950/what-are-c-functors-and-their-uses)
        在类中加一个operator()
        可以更加自定义化
        struct add_x {
			add_x(int val) : x(val) {}  // Constructor
			int operator()(int y) const { return x + y; }

		private:
			int x;
		};

		// Now you can use it like this:
		add_x add42(42); // create an instance of the functor class
		int i = add42(8); // and "call" it
		assert(i == 50); // and it added 42 to its argument
        4. 单继承/多重继承/虚继承
        5. [不同位置const的含义](https://stackoverflow.com/questions/1143262/what-is-the-difference-between-const-int-const-int-const-and-int-const)
        6. [constexpr与const](https://stackoverflow.com/questions/14116003/difference-between-constexpr-and-const)
	7. 单例模式. 
	A singleton gives you:
	1.Global access to an object, and
	2.A guarantee that no more than one object of this type can ever be created
	#include <iostream>
	class Singleton
	{
	public:
    		~Singleton(){
        	std::cout<<"destructor called!"<<std::endl;
    	}
    	Singleton(const Singleton&)=delete;
    	Singleton& operator=(const Singleton&)=delete;
    	static Singleton& get_instance(){
        	static Singleton instance;
        	return instance;

    	}
	private:
    	Singleton(){
        	std::cout<<"constructor called!"<<std::endl;
    	}
	};

	int main(int argc, char *argv[])
	{
    		Singleton& instance_1 = Singleton::get_instance();
    		Singleton& instance_2 = Singleton::get_instance();
    		return 0;
	}
	输出：constructor calls destructor calls
	
	
2. 内存管理
    1. 基础要求
        1. 指针、引用
        引用不可以为空，指针可以为空.
        当一个引用被初始化后，对象不会改变.引用不可以改变指向；但是指针可以改变指向，而指向其它对象.因此，引用比指针更安全.
	
	引用传递和值传递在函数参数中的区别.
	引用传递时在函数栈中开辟一块地址空间存放主调函数中实参的地址，当对其修改时直接从栈中找到主调函数的实参进行修改,就像间接寻址
	值传递是在函数的栈中开辟一块新的局部变量的地址空间将实参的值复制给这个局部变量.
	
        2. 内存对齐
        因为处理器在读取内存的时候，有内存读取粒度，一般为2的指数倍.不同变量类型在声明的
        时候内存是连续的.如果我不对齐，虽然会节省一部分空间，但在读取内存的时候将会特别
        麻烦.
        有效对其值：是给定值#pragma pack(n)和结构体中最长数据类型长度中较小的那个.
        内存对齐需要遵循的规则：
		(1) 结构体第一个成员的偏移量（offset）为0，以后每个成员相对于结构体首地址的 
		offset 都是该成员大小与有效对齐值中较小那个的整数倍，如有需要编译器会在成员之间
		加上填充字节。
		(3) 结构体的总大小为 有效对齐值 的整数倍，如有需要编译器会在最末一个成员之后加
		上填充字节。
		https://zhuanlan.zhihu.com/p/30007037
        3. 数组和指针；sizeof使用
        数组时存放多个相同数据类型的连续的地址空间.
        指针相当于一个变量，但是它和不同变量不一样，它存放的是其它变量在内存中的地址.
        int* arr[10];存放了10个整形类型的指针.
        int (*arr)[10];指向含有10个int型元素的数组的首地址的一个指针.
        数组名是常量不可修改
        sizeof（指针）永远是指针的大小，机器类型决定. 而sizeof（数组）时数组的元素个数乘元素大小
        
	
	
        4. new/new[]；delete/delete[]理解和使用
        其本质上是malloc和free的封装. new[]/delete[]在每个数据段的头部都会放入长、
        度.
        https://www.cnblogs.com/tp-16b/p/8684298.html
        5. shared_ptr使用
        为了防止内存泄漏（有指针指向时的内存被提前释放导致其变为野指针，没有任何指针指向的资源并没有释放，同一资源被释放多次）.
	使用一个引用计数的原理，用原子操作来保证线程安全.引用计数该shared_ptr新建一个指针指向一个含有count的实例，而后每个新的引用进来
	此实例加一，旧的引用消失此count减一,当count减为0时自动释放所指向的内存.
        6. [NULL和nullptr](https://stackoverflow.com/questions/1282295/what-exactly-is-nullptr)
        7. 左值与右值、左值引用和右值引用的概念
		左值引用：右边的值有地址.
		右值引用： 右边的值没有地址，如立即数，函数返回值
		右值引用可以使程序直接使用临时对象已经申请的资源
		https://winsoft666.blog.csdn.net/article/details/78520237?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2.no_search_link
		
	8.C++ 无符号整型与有符号整型越界问题
	(1)补码表示	(2) 无符号数越界时 wrap around. 有符号数越界最大值加一返回-最小值
	补码的思想其实就类似于生活中的时钟。
	正数的补码等于它的原码；负数的补码等于反码+1.
	接下来就做一做四位二进制数的减法（先不引入符号位）。
	0110-0010，6-2=4，但是由于计算机中没有减法器，没法算。
	这时候，想想时钟运算中，减去一个数，是可以等同于加上另外一个正数（同余数），这个数与减数相加正好等于模。
	也就是四位二进制数最大容量是多少？其实就是2^4=16（10000）。
	那么-2的同余数，就等于10000-0010=1110，16-2=14。
	既然如此，0110-0010=0110+1110=10100，6-2=6+14=20。
	按照这种算法得出的结果是10100，但是对于四位二进制数最大只能存放4位，如果低四位正好是0100，正好是想要的结果，至于最高位的1，计算机会把它放入	   psw寄存器进位位中，8位机会放在cy中，x86会放在cf中，这里不做讨论。
	这个时候，再想想在四位二进制数中，减去2就相当于加上它的同余数（至于它们为什么同余，还是建议看《计算机组成原理》）。
	但是减去2，从另一个角度来说，也是加上-2，即加上-2和加上14得到的二进制结果除了进位位，结果是一样的。如果我们把1110的最高位看作符号位后就    	     是-2的补码，这可能也是为什么负数的符号位是1，而不是0。
		
    2. 进阶要求
        1. new/delete 重载； placement new
        2. new/new[]；delete/delete[]实现原理，与malloc、free的关系
        3. [move理解与使用](https://stackoverflow.com/questions/3413470/what-is-stdmove-and-when-should-it-be-used)
        4. share_ptr实现思路
        5. 内存镜像：堆、栈、.data、BSS
        6. [memory order的概念](https://www.zhihu.com/question/24301047/answer/83422523)

3. 模板
    1. 基础要求
        1. 模板的基本使用：类、函数
        2. 模板的基本原理，与宏的区别
    2. 进阶要求
        1.  模板偏特化
        2.  模板元编程

4. 标准库
    1. 基础要求
        1. vecotr,list,queue基本操作、访问效率
        2. map,set基本操作
        3. iterator使用
        4. algorithm：sort，find
    2. 进阶要求
        1. vector,list,queue实现原理
        2. [string和wstring](https://stackoverflow.com/questions/402283/stdwstring-vs-stdstring)
        3. [vector的push_back和emplace_back](https://stackoverflow.com/questions/4303513/push-back-vs-emplace-back)
        4. [C++11的lambda](https://zh.cppreference.com/w/cpp/language/lambda)
        5. map/unordered_map;set/unordered_set对比、原理

5. IO
    1. 基础要求
        1. std::endl和'\n'的区别
        2. [文件IO使用](https://www.runoob.com/cplusplus/cpp-files-streams.html)
        3. 常用输入输出方式

6. 编译、运行、调试
    1. 基础要求
        1. 如何调试C++程序
        2. 头文件、源文件
        3. argc、argv
        4. [如何防止重复引用](https://zh.wikipedia.org/wiki/Include%E9%98%B2%E7%AF%84)
    2. 进阶要求
        1. C++异常处理机制
        2. [extern C作用](https://stackoverflow.com/questions/1041866/what-is-the-effect-of-extern-c-in-c)
        3. [gcc的O1,O2,O3优化](https://www.zhihu.com/question/27090458/answer/137944410)

#### Golang
1. 语法、数据结构
    1. 基础要求
        1. 结构体、指针、nil
        2. nil和空值的区别
        3. string和[]byte、slice和array、map、channel概念、使用
        4. golang对象池方案和解决的问题
        5. interface概念、应用
        6. go、defer、panic、recover
        7. init执行顺序
        8. 值传递、引用传递
    2. 进阶要求
        1. unsafe.Pointer
        2. 常用数据结构的内存结构及并发安全机制
        3. reflect作用和原理
        4. 闭包、作用域
        5. sync包的几种类型的实现：Map、Mutex等
        6. defer执行逻辑
            1. 参数和执行体
            2. 带命名返回值
2. 调度、并发
    1. 基础要求
        1. 控制并发地几种方式：channel、waitgroup、context
        2. 协程概念、使用场景、优缺点、开销
        3. 协程与进程、线程对比
    2. 进阶要求
        1. 常见并发方式的实现机制
        2. 如何理解通过通信实现共享
        3. channel的buffer
        4. 协程实现机制
        5. go内存模型、happens before原则
3. GC机制（进阶）
    1. GC基本过程、阶段
    2. 导致GC问题的影响因素、减少GC停顿时间的优化思路
    3. 常见优化GC方法
    4. Go的堆、栈与C的堆、栈区别
4. 性能优化
    1. 工具
        - trace
        - pprof
        - benchmark
    2. 思路
        - CPU
        - MEM

#### java
1. 基础：类、继承、多态、注解、泛型
    1. 基础要求：
        1. Interface/Class/Absract class 基本理解、使用
        2. 内部类使用，匿名/static
        3. 继承、多态、override
        4. 注解如何使用
        5. 泛型如何使用
    2. 进阶要求：
        1. 类加载机制（双亲委托）
        2. 类标识：全名+ClassLoader
        3. Annotation Processing
        4. 泛型实现机制，“类型擦除”理解
        5. 非static内部类访问外部类成员/方法的原理（Outer.this,对private生成access方法）
2. 常用标准库：List/ArrayList/LinkedList; Map/Hashtable/LinkedHashMap; 迭代器
    1. 基础要求：
        1. 熟悉常用的容器类基本使用
        2. ==与equals区别，Object的hashcode/equals的理解和使用
    2. 进阶要求：
        1. 了解特性、实现原理
        2. concurrent包对应实现的了解
        3. ConcurrentModificationException
3. 并发编程
    1. 基础要求
        1. 反射基本理解、使用
        2. primitive types 和 object type
        3. 常见引用类型：强、软、弱
        4. gc基本机制和算法（能说出大体思路）
        5. GCRoot
        6. jvm基本概念，与进程关系，字节码、解释执行/JIT基本概念
    2. 进阶要求
        1. 不同引用类型的具体差异、使用，如ReferrenceQueue等
        2. 详述内存管理机制和算法，新生代/老年代，minor gc / full gc
        3. 字节码生成、修改
        4. 动态代理

## 算法思维
最重要的模块之一，考察面试者的思考能力、对底层数据结构的理解能力、对时间/空间复杂度的分析能力。
主要有三种考察方式
- 问答题，知识简答
- 算法题，解决题目并编写代码
- 设计/思维题，表达想法，一般不需要写代码

应充分展现自己的思考过程，不一定需要直接想出最优解；
没有进展的情况下面试官通常会给出提示

## 基础知识
考察计算机必修课相关知识，要做到入门知识都了解，基础知识会70%以上，进阶知识尽可能多学一些。

### 大纲
- 操作系统
  - 字符编码
    - 基础
      - Unicode和ANSI区别
      Unicode 是世界性字符集
    - 进阶
      - utf-8 中，英文，汉字各占几个字节
      英文占一个，中文占3到4个
  - 进程和线程
    - 入门
      - 进程和程序的区别
      1）程序是永存的；进程是暂时的，是程序在数据集上的一次执行，有创建有撤销，存在是暂
      时的；
	 （2）程序是静态的观念，进程是动态的观念；
     （3）进程具有并发性，而程序没有；
     （4）进程是竞争计算机资源的基本单位，程序不是。
     （5）进程和程序不是一一对应的： 一个程序可对应多个进程即多个进程可执行同一程序； 一
      个进程可以执行一个或几个程序
      - 进程和线程的关系
      线程在进程下行进（单纯的车厢无法运行）一个进程可以包含多个线程（一辆火车可以有多个
      车厢）不同进程间数据很难共享（一辆火车上的乘客很难换到另外一辆火车，比如站点换乘）
      同一进程下不同线程间数据很易共享（A车厢换到B车厢很容易）进程要比线程消耗更多的计算
      机资源（采用多列火车相比多个车厢更耗资源）进程间不会相互影响，一个线程挂掉将导致整
      个进程挂掉（一列火车不会影响到另外一列火车，但是如果一列火车上中间的一节车厢着火了
      ，将影响到所有车厢）
      进程使用的内存地址可以上锁，即一个线程使用某些共享内存时，其他线程必须等它结束，才能
      使用这一块内存。－"互斥锁" 进程使用的内存地址可以限定使用量－“信号量”

		clone要快于fork
	  线程比进程创建快,线程之间可以很轻易的共享数据
      
      进程是指令执行序列和存储资源的集合.执行序列就是线程.
      线程之间共享一套mmu，共享相同的页表页目录进而相同的物理地址
      Linux中 不同线程之间（同一进程内）共享相同的内存但愿（相同的页目录页表物理地址....） 不同进程间虽然可能虚拟地址相同，映射关系不可能相同
      （不同的页目录页表和内存地址）

      Linux fork()原理.读时共享，写时复制！尽量节省资源.
    - 基础
      - 线程同步机制
      互斥锁
      1表示加锁，加锁状态下只有该线程运行并修改数据，操作完毕后解锁.
      条件变量
      描述某些资源就绪与否的状态，为了实现同步而引入。同步是以互斥为前提的。首先获取锁，
      遇到条件变量时将进程阻塞并释放锁，一旦条件为真时返回再获取锁.目的，避免线程不断轮询
      检查条件成立而降低效率.
      - 死锁原理
      产生死锁的原因.
      1.critcial section（相互竞争的资源），不可剥夺的，相互竞争的
      2.线程间顺序的不当执行
      死锁的条件
      1.互斥
      2.请求和保持
      3.不剥夺
      4.环路等待
      - 抢占式进程调度和进程优先级
      优先级调度算法又称优先权调度算法，该算法既可以用于作业调度，也可以用于进程调度，该
      算法中的优先级用于描述作业运行的紧迫程度。
	  在作业调度中，优先级调度算法每次从后备作业队列中选择优先级最髙的一个或几个作业，将
	  它们调入内存，分配必要的资源，创建进程并放入就绪队列。在进程调度中，优先级调度算法
	  每次从就绪队列中选择优先级最高的进程，将处理机分配给它，使之投入运行。
	  根据新的更高优先级进程能否抢占正在执行的进程，可将该调度算法分为：
      非抢占式优先级调度算法。当某一个进程正在处理机上运行时，即使有某个更为重要或紧迫的
      进程进入就绪队列，仍然让正在运行的进程继续运行，直到由于其自身的原因而主动让出处理
      机时（任务完成或等待事件），才把处理机分配给更为重要或紧迫的进程。
      抢占式优先级调度算法。当一个进程正在处理机上运行时，若有某个更为重要或紧迫的进程进
      入就绪队列，则立即暂停正在运行的进程，将处理机分配给更重要或紧迫的进程。
      而根据进程创建后其优先级是否可以改变，可以将进程优先级分为以下两种：
      静态优先级。优先级是在创建进程时确定的，且在进程的整个运行期间保持不变。确定静态优
      先级的主要依据有进程类型、进程对资源的要求、用户要求。
      动态优先级。在进程运行过程中，根据进程情况的变化动态调整优先级。动态调整优先级的主
      要依据为进程占有CPU时间的长短、就绪进程等待CPU时间的长短。
      -----------
      栈变量是私有的，全局和静态变量是共享的，本地自动变量也可以通过参数传递共享
    - 进阶
      - 原子操作原理
      两个i++时
      多核情况下对于共享内存，因为各自的核里面有各自的缓存.导致缓存中没法加两次，各自加了
      一次写入内存.单核情况下，两个线程在操作时，因为自己的线程有自己的栈空间，上下文中也
      保存了相应的自己的寄存器的值（如eax），在inc eax时从另外一个线程返回时重新载入自
      己的切换出去时的值是原先的而并没是操作过后的.所以不安全.
      单核时，加锁就可.
      多核时.
      1.使用总线锁.
      2.使用缓存锁.
      - volatile解决什么问题
      禁止编译器将该变量优化到寄存器中.
      比如等待在IO操作时，某个循环的判断条件是由某个中断引起的，可能编译器会将这个变量优化到
      程序寄存器中，如果这样，外部中断有可能永远也无法访问并修改该变量这使这个循环成为死循环.
      加入volatile就将该变量限定在内存中使用.这样就不会造成上述结果.
      - 互斥锁、信号量、临界区、循环锁区别联系、使用场景
      互斥锁，存在线程的上下文切换，
      信号量，值不为一的互斥锁.
      临界区：访问共享单元的代码区
      循环锁：一个循环中不停检查是否能获取该锁，没有线程上下文切换，但消耗cpu
      从线程运行的状态的角度.互斥锁是将运行态变为阻塞态. 而自旋锁实际上一直在运行态中.
      CPU被完全占用. 当线程切换代价特别大时，用自旋锁，而当要锁的内容特别多时，用互斥锁
      好一些.
      条件变量用于解决等待问题，使CPU不用轮询检查是否需要加锁.
      - 读写锁怎么实现
      当读写锁被加了写锁时，其他线程对该锁加读锁或者写锁都会阻塞（不是失败）。
	  当读写锁被加了读锁时，其他线程对该锁加写锁会阻塞，加读锁会成功。
      - 设计实现线程池
      
      - 动态链接、静态链接区别
      https://www.cnblogs.com/gaoyihan/p/4723332.html
      
  - 内存管理：
    - 入门
      - 堆&栈
	堆-由程序员分配释放，若程序员不释放，程序结束时可能由OS回收。
        栈-由编译器自动分配释放，存放函数的参数值，局部变量等。
        区别-1). 管理方式不同。2).空间大小不同，一般来说，进程拥有的栈的大小远远小于堆的大小，理论上，进程可以申请的堆的大小为虚拟内存大小，进程栈的大小依据不同系统的设置:64位windows默           认为1MB，64位linux默认为10mb。3).生长方向不同。堆的生长方向由内存地址由低到高，栈相反。4).堆只能动态分配，栈可以动态或静态分配。5).存放内容不同。
    - 基础
      - 虚拟内存(Virt) & 常驻内存(Resident) & 共享内存 (Shared)
      https://www.cnblogs.com/xuxm2007/archive/2012/06/05/2536294.html
      - mmap
      https://www.cnblogs.com/huxiao-tee/p/4660352.html
      - 匿名映射 & 命名映射
	匿名映射就是mmap一块未使用过的空间
      - Free & Available 
	[root@VM_16_17_centos bin]# free 
              total        used        free      shared  buff/cache   available
Mem:        1882892      785272      280428       40496      817192      852060
Swap:             0           0           0
        free 与 available 的区别
	free 是真正尚未被使用的物理内存数量。
	available 是应用程序认为可用内存数量，available = free + buffer + cache (注：只是大概的计算方法)

	Linux 为了提升读写性能，会消耗一部分内存资源缓存磁盘数据，对于内核来说，buffer 和 cache 其实都属于已经被使用的内存。但当应用程序申请内存时，如果 free 内存不	   够，内核就会回收 buffer 和 cache 的内存来满足应用程序的请求。

	作者：不做秃顶的程序猿
	链接：https://www.jianshu.com/p/2ffeb3a3aa90
	来源：简书

      - Buffer & Cached 
	cache 计算机体系中介于CPU和主存之间，可用于存放那些经常使用的资源。CPU读写cache的速度更快一些，这样，根据程序局部性原理。加入cache可以暂时存放那些常用的资源进        而CPU无需与主存频繁交互以提高处理能力.比如网页cache会缓存最近经常使用的网页。这样无需重新下载内容。buffer应对的是生产消费模型资源给予与消耗速率不一致或者需要规        定使用大小时.比如网络通信时的TCP buffer。这个可以来暂存那些还未被消费者使用的数据，还可以用来存放并验证数据的完整性。或者比如说内存和磁盘交互时，磁盘每次存取是按        块来每块4Kb可能。这样你写入大数据时每次准备4kb写入在准备4kb。buffer可以起到一个规定资源单位的作用.
	
	![image](https://user-images.githubusercontent.com/91724438/153133116-ad5c6cc1-e153-4923-8e25-c5bb4594c0d6.png)

	cache：文件系统层级的缓存，从磁盘里读取的内容是存储到这里，这样程序读取磁盘内容就会非常快，比如使用grep和find等命令查找内容和文件时，第一次会慢很多，再次执行就	      快好多倍，几乎是瞬间。但如上所说，如果对文件的更新不关心，就没必要清cache，否则如果要实施同步，必须要把内存空间中的cache clean下
	buffer：磁盘等块设备的缓冲，内存的这一部分是要写入到磁盘里的。这种情况需要注意，位于内存buffer中的数据不是即时写入磁盘，而是系统空闲或者buffer达到一定大小统一	写到磁盘中，所以断电易失，为了防止数据丢失所以我们最好正常关机或者多执行几次sync命令，让位于buffer上的数据立刻写到磁盘里。
	
      - 伪共享
        CPU加载缓存的基本单位是cache line. 每个cache line一般包含多个变量并且这些变量大多都是连续的. 当一个多核CPU某个核心线程使用cache line其中的一个数据的时候，意	味着其他邻近的变量也会读进这个cache line. 而这时，因为缓存一致性协议，当另一个cpu核的另一个线程在使用它(前面用到的那个数据)相邻的变量时，虽然他在缓存中但他依然不       可以用因为这个cache line已经被修改过了.这时他只能再次从内存读取相应的数据.产生性能开销.
	
	当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，导致无法充分利用缓存行特性，这就是伪共享
	伪共享问题其实是由于高速缓存的特性引起的，三级高速缓存中的数据并不是一个变量一个变量单独存放的，它的基本存储单元是 Cache Line，一般一个 Cache Line 的大小是 64 	     字节，也就是说，一个 Cache Line 中可以存下 8 个 8 字节的 long 类型变量那由于高速缓存的基本单元是 64 字节的 Cache Line，所以呢，缓存从内存中一次读取的数据就是         64 字节。换句话说，如果 cpu 要读取一个 long 类型的数组，读取其中一个元素的同时也会把接下来的其他相邻地址的七个元素也加载到 Cache Line 中来。
        这就会导致一个问题，举个例子，我们定义了两个 long 类型的变量 a 和 b，他们没有关系，但是他们在内存中的地址是紧挨着的，如果一个 CPU 核心的线程 T1 在对 a 进行修         改，另一个 CPU 核心的线程 T2 却在对 b 进行读取。那么当 T1 修改 a 的时候，除了把 a 加载到 Cache Line，还会把 b 同时也加载到 T1 所处 CPU 核心的 Cache Line 中         来，对吧。
        根据 MESI 缓存一致性协议，修改完 a 后这个 Cache Line 的状态就是 M（Modify，已修改），而其它所有包含 a 的 Cache Line 中的 a 就都不是最新值了，所以都将变为 I         状态（Invalid，无效状态）这样，当 T2 来读取 b 时，他就会发现，他所处的 CPU 核心对应的这个 Cache Line 已经失效了，这样他就需要花费比较长的时间从内存中重新加载         了。
        也就是说，b 和 a 没有任何关系，每次却要因为 a 的更新导致他需要从内存中重新读取，拖慢了速度。这就是伪共享
        于伪共享，一般有两种方法，其实思想都是一样的：
        1）padding：就是增大数组元素之间的间隔，使得不同线程存取的元素位于不同的缓存行上，以空间换时间。比如在 a 和 b 之间再定义 7 个 long 类型的变量，使得 a 和 b 不         在一个 Cache Line 上，这样当修改 a 的时候 b 所处的 Cache Line 就不会受到影响了

        作者：飞天小牛肉
        链接：https://leetcode-cn.com/circle/discuss/oagUUD/
        来源：力扣（LeetCode）

      - Huge Page的作用和利弊
	优点很明显，大页内存TLB miss 很少，缺页中断也很少，极高的提高了性能，对于那些内存操作非常频繁的业务来说，可以有效的提高性能。
        缺点就是，大页内存类似专用内存，会从系统中抠出一块大内存（pagesize*nr_pages），而想要使用这块内存，应用程序必须修改程序，使用上述几种方式来使用大页。 其次，如         果程序内存使用较少，却申请了大页，就造成了内存浪费的。

	版权声明：本文为CSDN博主「Mrpre」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
	原文链接：https://blog.csdn.net/mrpre/article/details/83586778
      - X86的虚拟地址，物理地址，逻辑地址
	虚拟地址：物理地址：逻辑地址：逻辑
	虚拟地址是由程序产生的由段选择符和段内偏移地址组成的地址。这两部分组成的地址并没有直接访问物理内存，而是要通过分段地址的变换处理后才会对应到相应的物理内存地址。
	逻辑地址指由程序产生的段内偏移地址。有时把逻辑地址当成虚拟地址，两者并没有明确的界限。
	线性地址是指虚拟地址到物理地址变换的中间层， 是处理器可寻址的内存空间（称为线性地址空间）中的地址。程序代码会产生逻辑地址，或者说段中的偏移地址，加上相应段基
	址就生成了一个线性地址。如果启用了分页机制，那么线性地址可以再经过变换产生物理地址。若是没有采用分页机制，那么线性地址就是物理地址。
	物理地址是指现在 CPU 外部地址总线上的寻址物理内存的地址信号，是地址变换的最终结果。
	虚拟地址到物理地址的转换方法是体系结构相关的，一般分段与分页两种方式。以X86CPU为例：
	分段分页都是支持的。内存管理单元负责从虚拟地址到物理地址的转化。逻辑地址是段标识+段内偏移 MMU（内存管理单元） 通过查询段表，可以把逻辑地址转换为线性地址。
	如果CPU没有开启分页功能，线性地址就是物理地址；如果CPU开启了分页功能，MMU还需要查询业表来将线性地址转换为物理地址；
	逻辑地址(段表）--------> 线性地址（页表）------------->物理地址。
	映射是一种多对一的关系，即不同的逻辑地址可以映射到同一个线性地址上；
	不同的线性地址也可以映射到同一个物理地址上。而且同一个线性地址在发生变化后，也可能被重新装载到另外一个物理地址上，所以这种多对一的关系也会随时间发生变化。
	多级页表从两个方面减少了存储器要求。
	第一，如果一级页表中的第一个PTE（分页）是空的，那么相应的二级页表就根本不会存在，这代表着一种巨大的潜在节约，因为对于一个典型的程序，比如4GB,8GB的虚拟地址空间的	     大部分都将是未匹配的。
	第二，只有一级页表才需要总是在主存中；虚拟存储器系统可以在需要时创建，页面掉入或调出二级页表，这就减少了主存的压力；只有最经常使用的二级页表才需要缓存在主存中，         这种离散的存储方式是非常便利的离散化了。
	————————————————
	版权声明：本文为CSDN博主「异构计算大师」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
	原文链接：https://blog.csdn.net/qq_43325061/article/details/119060604
	
      - 内存回收过程
	https://zhuanlan.zhihu.com/p/70964195
	https://zhuanlan.zhihu.com/p/72998605
    - 进阶
      
	- 虚拟地址和物理地址的翻译(MMU & TLB)
	![image](https://user-images.githubusercontent.com/91724438/153858561-e45d8db2-a13e-4460-9fba-fd0653c678a2.png)
	![image](https://user-images.githubusercontent.com/91724438/153858990-e1499038-8458-4341-a8dd-94d601a0d00e.png)
      
	- Drop Cache以后可用内存不增加的主要原因
	dirty pages不能回收；
	共享内存和tmpfs不能回收(注意观察free命令显示的shared值)
      
	- 进程和线程内存地址空间的区别
	进程的地址空间不同（物理地址不同，虚拟地址空间有可能相同的映射一般不相同）同一进程内的不同线程拥有着相同的地址空间.
      
	- Buddy分配器 & Slab分配器
	第一种：以页为单位分配内存，一次申请内存的长度必须是页的整数倍
	第二种：按需分配内存,一次申请内存的长度是随机的。
	出于空间效率：页的长度太小，会增加系统管理负担，一般页长度为4KB。举个例子：open系统调用中，用file数据结构描述被打开的文件。存放file数据结构需要的内存远远小于一	       个页，如果没有slab子系统，内核只有通过buddy子系统申请一个完整的页。一部分给file数据结构用，剩下的内存有两种方法处理。其一：open流程管理剩余内存，留作它用。如果         内核的所有函数都要自己管理这种剩余内存，内存管理代码会分散到系统各个地方，显然是不科学的。其二：将每一个file装到一个页中，这个页剩余的内存不要了，这样会浪费内存         空间。
        出于时间效率：buddy子系统相对于slab子系统复杂很多，每次调用alloc_pages和free_pages要付出惨重代价。内核中有些代码又必须频繁申请释放内存。slab充当内核各个子系         统和buddy子系统之间的空闲内存“缓冲池”。内存被kfree释放后，短时期停留在slab子系统中，再次kmalloc时，直接从slab分配。避免每次内存分配释放都调用alloc_pages和           free_pages。
        既然有了slab子系统，是不是所有的内存分配都经过slab子系统接口分配？  
	1.slab子系统时为了内核申请内存专门设计的，比如应用程序缺页还是要通过alloc_pages和free_pages申请内存。
	2.内核中很多子系统必须通过alloc_pages和free_pages直接分配物理上连续的内存页。
	3.另外一点slab子系统申请的内存一定在NORMAL区或DMA区，分配不到HIGHMEM区的内存，而alloc_pages和free_pages能分配到HIGHMEM区的内存
	slab子系统调用alloc_pages申请完整页，然后将这些页切分成小段内存，slab是怎么将这些个小段内存管理起来的呢？
        - 内存碎片 & 内存整理
        内存碎片的分类:1)内部碎片-指分配给用户的内存空间中未被使用的部分。例如进程需要使用3K bytes物理内存，于是向系统申请了大小等于3Kbytes的内存，但是由于Linux内核伙伴系统算法最小颗粒是         4K bytes，所以分配的是4Kbytes内存，那么其中1K bytes未被使用的内存就是内存内碎片。2)外部碎片-指系统中无法利用的小内存块。例如系统剩余内存为16K bytes，但是这16K bytes内存是由4个4K         bytes的页面组成，即16K内存物理页帧号#1不连续。在系统剩余16K bytes内存的情况下，系统却无法成功分配大于4K的连续物理内存，该情况就是内存外碎片导致。
        何时需要内存整理:{内核从伙伴系统以min阀值获取连续页框，但是连续页框又不足时。
	当需要从指定地方获取连续页框，但是中间有页框正在使用时。
	因为内存短缺导致kswapd被唤醒时，在进行内存回收之后会进行内存碎片整理。
	#将1写入sysfs中的/vm/compact_memory时，系统会对所有zone进行内存碎片整理。}
        内存整理的流程概括:从目标内存区段的前面扫描可移动的页框，从内存区段后面向前扫描空闲的页框，两边扫描结束后，将可移动的页框放入到空闲页框中。
	
	
- 网络
  - 通用知识：
    - 入门
      - 4网络协议基本概念
    - 基础
      - 7层网络协议的基本概念，常用网络协议属于第几层？
      - 常见设备工作在那一层？(路由器、交换机、网桥)
      - json 格式描述
    - 进阶
      - protobuff 协议了解
      - 整个网络过程串联(一个请求整个网络的处理过程)
  - 网络层：
    - 入门
      - IPv4地址样例。
      - 子网掩码的作用。
      - 给定 ip 和 子网掩码，广播地址是什么？
    - 基础
      - 列举IP报文头部(源地址、目标地址、TTL)
    - 进阶
      - IPv6 的基本概念
      - 为什么引入 IPV6。
      - BGP、OSPF协议原理
  - 传输层：
    - 入门
      - TCP 和 UDP 各自的特点和区别；
      - TCP 和 UDP 各自适合的使用场景
    - 基础
      - TCP 建立连接和断开连接的过程
      - TCP和UDP的头部列举
    - 进阶
      - 什么是SYN 攻击？A（攻击者）发送TCP SYN，SYN是TCP三次握手中的第一个数据包，而当这个服务器返回ACK以后，A不再进行确认，那这个连接就处在了一个挂起的状态，也就是半连接的意思，那么	  服务器收不到再确认的一个消息，还会重复发送ACK给A。这样一来就会更加浪费服务器的资源。A就对服务器发送非法大量的这种TCP连接，由于每一个都没法完成握手的机制，所以它就会消耗服务器的	    内存最后可能导致服务器死机，就无法正常工作了。更进一步说，如果这些半连接的握手请求是恶意程序发出，并且持续不断，那么就会导致服务端较长时间内丧失服务功能——这样就形成了DoS		攻击。这种攻击方式就称为SYN泛洪攻击。
	那么我们如何去防范这种SYN攻击呢？
	其实最常用的一个手段就是优化主机系统设置。比如降低SYN timeout时间，使得主机尽快释放半连接的占用或者采用SYN cookie设置，如果短时间内收到了某个IP的重复SYN请求，我们就认为受到	   了攻击。我们合理的采用防火墙设置等外部网络也可以进行拦截。
      - TCP为什么三次握手 而需要 四次挥手？
        如果少了其中任何一次，总有一方不能可靠的通知对方自己的数据已发送完毕. Server 需要告知 client 将所有数据发送完毕后再关闭
      - 滑动窗口概念
        为了更大的利用带宽 如果一次发一个响应比较慢 一个窗口可以使对端充分缓冲处理数据
	![Z({3W2IENUGEW2{0J0O M`9](https://user-images.githubusercontent.com/91724438/145159800-d4821d66-d2ea-4bfb-a998-08ce771a3e25.png)
      - 慢启动
        运输层
	端对端在开始通信时并不能知道网络状态，用慢启动方式来探测当前网络状态并进而充分利用网络资源.
	
      - 拥塞控制
       快恢复 拥塞避免
       在收到3个冗余ack时执行快速恢复算法.
       在超时时执行慢启动算法
       二者都将窗口阈值改为一半
       
       区别于流量控制 流量控制为了防止接收端的处理速度过慢导致buffer溢出进而丢包
       ![12E_~%V~4}MY0IH6EB2P9 E](https://user-images.githubusercontent.com/91724438/145162315-1162c2a8-1693-4cea-b8b1-a73a0ffd1cc4.png)

  - DNS  ：
    - 入门
      - DNS用途
     人们更喜欢便于记忆的主机名字而路由器更喜欢定长的ip地址 DNS就是完成主机名到IP地址的映射
    - 基础
      - 描述 DNS 过程
      - 一台用户主句运行着DNS应用的客户端
      - 浏览器抽取主机名传给DNS客户端
      - DNS客户端向dns服务器发送包含主机名的请求
      - DNS服务器检查缓存是否有映射如果有直接返回当前IP如果没有继续查询
      - DNS客户端最终会收到回答报文.里面包含IP地址
    
    - 进阶
      - 列举典型的DNS记录格式
      查询和回答报文
      1.标识符.2.标志（查询或者回答）.
      - DNS 劫持概念，如何防止 DNS 劫持？
      DDoS 向dns服务器发送大量的DNS请求.
      - 主流的公有云的DNS服务端架构
      不知道
  - 应用层 ：https://hit-alibaba.github.io/interview/basic/network/HTTP.html
    - 入门
      - https 加密过程.
      SSL 加密
      用非对称加密加密对称加密共享钥匙从而用对称加密进行通信
      详细过程
      ![图片](https://user-images.githubusercontent.com/91724438/145710268-a7b224d1-4560-4378-a93b-3086f3327911.png)

      hash和加密不同
      
      - http协议的用途，列举一些使用场景
      
      传输HTML文件 客户端浏览器与web服务器的应用层通信协议
      
      - 举例常见应用层协议
      
      http
      - http和https区别
      ![4UD6PXCVY@H@)H(6O`18K@F](https://user-images.githubusercontent.com/91724438/145165089-51644718-8fa6-4c80-b7dd-858209dbe2e8.png)

    - 基础
      - header 中：Content-Type / Content-Length / Content-Encoding：用途
       content-type: text 还是image
       content length：被发送对象的字节数
       content-encoding：web服务器支持的返回内容压缩编码类型。
      - header，cookie，返回码，UA，HOST，域 等基本概念；
       
      - POST/GET 区别；
      
	
    GET提交的数据会放在URL之后，以?分割URL和传输数据，参数之间以&相连，如EditPosts.aspx?name=test1&id=123456. POST方法是把提交的数据放在HTTP包的Body中.

    GET提交的数据大小有限制（因为浏览器对URL的长度有限制），而POST方法提交的数据没有限制.

    GET方式需要使用Request.QueryString来取得变量的值，而POST方式通过Request.Form来获取变量的值。

    GET方式提交数据，会带来安全问题，比如一个登录页面，通过GET方式提交数据时，用户名和密码将出现在URL上，如果页面可以被缓存或者其他人可以访问这台机器，就可以从历史记录获得该用户的账号和密码.
	1.我们前面说，无论是GET请求还是POST请求，其本质都是不安全的，为什么这样说呢?如果
仅仅从GET请求的参数在地址栏是可见的，POST 是不可见的，那就太肤浅了。由于HTTP自
己本身是一个明文协议，每个HTTP请求和返回的数据在网络上都是明文传播，无论是url、
header还是body。只要在网络节 点捉包，就能获取完整的数据报文,要防止泄密的唯一手段
就是使用HTTPS (用 SSL协议协商出的密钥加密明文HTTP数据)。
2.为什么在浏览器中GET 请求方式的url长度有限制呢?这是因为浏览器要对url 进行解析，而
解析的时候就要分配内存。对于-个字节流的解析,必须分配buf fer来保存所有要存储的数
据。而url这种东西必须当作一个整体看待， 无法一块一块处理，于是就处理一个请求时必须
分配一整块足够大的内存。如果url太长，而并发又很高，就容易挤爆服务器的内存。
3. POST 是发送两个请求吗?.上面提到 POST请求可以被分为“请求头” 和“请求体”两个部分，
那这两部分是-起发送出去呢?还是先发“请求头”，再发“请求体”呢?在HTTP协议中并
没有明确说明POST 会产生两个数据包。之所以会发两个数据包，则是出于以下考虑:如果服务
器先收到“请求头”，则会对其进行校验，如果校验通过，则回复客户端”100 -
Continue”，客户端再把”请求体“发给服务器。如果请求被拒了，服务器就回复个400之类
的错误，这个交互就终止了。这样做的优点是可以避免浪费带宽传输请求体，但是代价就是会
多-次Round Trip。如果刚好请求体的数据也不多，那么一次性全部发给服务器可能反而更
好。所以说，这和POST完全没有关系，只是基于两端的一种优化手段罢了。
      - 常见返回码含义；
    - 进阶
      - http2.0 和 http1.1 的主要区别？
      - GET 的幂等的含义；
      - keep-alive 含义；
      - 为什么需要 url 编码？
      - 实现断点续传的原理；
      - https协商过程
      - CSRF（Cross-site request forgery，跨站请求伪造）：原理和防范
      - XSS（Cross Site Scripting，跨站脚本攻击）：原理和防范
      - 中间人攻击概念与防止。
      - QUIC、Http2特点
- 数据库
  - 入门：
    - 写个简单的查询语句。
    - 事务，索引，主键等的概念。
    - join，group by 的作用和使用场景。
  - 基础：
    - 数据库三个范式的定义。
    - 数据库游标干什么用的？
    - CAP 概念和原理？
  - 进阶：
    - 列举自己用过的数据库及其特点。
    - 针对应聘者用过的一个数据库，详细问其中的一些原理或者使用方法。
4.  
Select Epoll

Select. 1.单个进程监听的描述符有限制2.仅仅知道IO事件发生时并不知道哪几个流，只能无差别轮询3.需要用户态向内核态的拷贝，有一个很大的fd的数据结构.

Epoll. 1.没有最大链接限制2.只有活跃的fd才会调用回调函数，无需轮询3.利用mmap()加速了内存拷贝.

Select中进程只有在调用一定方法后，内核才对所有监视的文件描述符进行扫描.
而epoll因为有回调机制，一旦就绪后就可以放到epoll_wait()里面
	
	
	
B树 B+树 与红黑树
B 树： 
1 m个孩子.
2. m-1关键字按序排列 
3.除根节点外，其他每个分支节点至少有ceil（m/2）子树
4.根节点至少含有两个孩子
计算高度时注意 
pre condition:
	n>=1，则对于任意一棵包含n个关键字、高度为h、阶数为m的B树。
![image](https://user-images.githubusercontent.com/91724438/148650767-8af257bd-36ee-4602-b7e6-74e2b8f5b2c9.png)

![image](https://user-images.githubusercontent.com/91724438/148650755-f14221ce-eb4b-4752-8491-517834fef23b.png)


typedef struct {
    /*文件数*/
    int  file_num;
    /*文件名(key)*/
    char * file_name[max_file_num];
    /*指向子节点的指针*/
     BTNode * BTptr[max_file_num+1];
     /*文件在硬盘中的存储位置*/
     FILE_HARD_ADDR offset[max_file_num];
}BTNode;
假如每个盘块可以正好存放一个B树的结点（正好存放2个文件名）。那么一个BTNODE结点就代表一个盘块，而子树指针就是存放另外一个盘块的地址。
![image](https://user-images.githubusercontent.com/91724438/148649103-dacd680c-3a9d-4e5d-8b37-8de20ca828e5.png)

下面，咱们来模拟下查找文件29的过程：

根据根结点指针找到文件目录的根磁盘块1，将其中的信息导入内存。【磁盘IO操作 1次】    
此时内存中有两个文件名17、35和三个存储其他磁盘页面地址的数据。根据算法我们发现：17<29<35，因此我们找到指针p2。
根据p2指针，我们定位到磁盘块3，并将其中的信息导入内存。【磁盘IO操作 2次】    
此时内存中有两个文件名26，30和三个存储其他磁盘页面地址的数据。根据算法我们发现：26<29<30，因此我们找到指针p2。
根据p2指针，我们定位到磁盘块8，并将其中的信息导入内存。【磁盘IO操作 3次】    
此时内存中有两个文件名28，29。根据算法我们查找到文件名29，并定位了该文件内存的磁盘地址。
分析上面的过程，发现需要3次磁盘IO操作和3次内存查找操作。

B树用中序遍历可以扫库（从小到大根据key查范围），但是这样会大大增加磁盘的IO次数。 基于此B+树利用双向链表方便扫库.更适合range query.


红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多
	
局部性原理与磁盘预读：
由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理： 
当一个数据被用到时，其附近的数据也通常会马上被使用。 
程序运行期间所需要的数据通常比较集中。 
由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。

	基于局部性原理，明显二叉树都不合适作为磁盘存储的数据结构，所以多叉树和磁盘预读都是必要的.
	
B+树
链表将叶子节点连接便于range query.除叶子节点外只存索引
	
